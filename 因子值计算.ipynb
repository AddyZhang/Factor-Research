{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 筛股票"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Unable to import required dependencies:\nnumpy: \n\nIMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE!\n\nImporting the multiarray numpy extension module failed.  Most\nlikely you are trying to import a failed build of numpy.\nHere is how to proceed:\n- If you're working with a numpy git repository, try `git clean -xdf`\n  (removes all files not under version control) and rebuild numpy.\n- If you are simply trying to use the numpy version that you have installed:\n  your installation is broken - please reinstall numpy.\n- If you have already reinstalled and that did not fix the problem, then:\n  1. Check that you are using the Python you expect (you're using /Users/Zhang/anaconda3/bin/python),\n     and that you have no directories in your PATH or PYTHONPATH that can\n     interfere with the Python and numpy versions you're trying to use.\n  2. If (1) looks fine, you can open a new issue at\n     https://github.com/numpy/numpy/issues.  Please include details on:\n     - how you installed Python\n     - how you installed numpy\n     - your operating system\n     - whether or not you have multiple versions of Python installed\n     - if you built from source, your compiler versions and ideally a build log\n\n     Note: this error has many possible causes, so please don't comment on\n     an existing issue about this - open a new one instead.\n\nOriginal error was: dlopen(/Users/Zhang/anaconda3/lib/python3.7/site-packages/numpy/core/_multiarray_umath.cpython-37m-darwin.so, 2): Library not loaded: @rpath/libopenblas.dylib\n  Referenced from: /Users/Zhang/anaconda3/lib/python3.7/site-packages/numpy/core/_multiarray_umath.cpython-37m-darwin.so\n  Reason: image not found\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-1bdac29e0691>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# 转化hdf5格式数据到DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mread_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.h5'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmissing_dependencies\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     raise ImportError(\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0;34m\"Unable to import required dependencies:\\n\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_dependencies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     )\n\u001b[1;32m     19\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mhard_dependencies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdependency\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmissing_dependencies\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: Unable to import required dependencies:\nnumpy: \n\nIMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE!\n\nImporting the multiarray numpy extension module failed.  Most\nlikely you are trying to import a failed build of numpy.\nHere is how to proceed:\n- If you're working with a numpy git repository, try `git clean -xdf`\n  (removes all files not under version control) and rebuild numpy.\n- If you are simply trying to use the numpy version that you have installed:\n  your installation is broken - please reinstall numpy.\n- If you have already reinstalled and that did not fix the problem, then:\n  1. Check that you are using the Python you expect (you're using /Users/Zhang/anaconda3/bin/python),\n     and that you have no directories in your PATH or PYTHONPATH that can\n     interfere with the Python and numpy versions you're trying to use.\n  2. If (1) looks fine, you can open a new issue at\n     https://github.com/numpy/numpy/issues.  Please include details on:\n     - how you installed Python\n     - how you installed numpy\n     - your operating system\n     - whether or not you have multiple versions of Python installed\n     - if you built from source, your compiler versions and ideally a build log\n\n     Note: this error has many possible causes, so please don't comment on\n     an existing issue about this - open a new one instead.\n\nOriginal error was: dlopen(/Users/Zhang/anaconda3/lib/python3.7/site-packages/numpy/core/_multiarray_umath.cpython-37m-darwin.so, 2): Library not loaded: @rpath/libopenblas.dylib\n  Referenced from: /Users/Zhang/anaconda3/lib/python3.7/site-packages/numpy/core/_multiarray_umath.cpython-37m-darwin.so\n  Reason: image not found\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# 转化hdf5格式数据到DataFrame\n",
    "def read_data(name):\n",
    "    file = name + '.h5'\n",
    "    store = pd.HDFStore(file, mode='r')\n",
    "    data = store.select('data')\n",
    "    store.close()\n",
    "\n",
    "    ticker_list = [ticker for ticker in data.columns if ticker[0] in ['0', '3', '6']]\n",
    "    output = data[ticker_list]\n",
    "    return output\n",
    "\n",
    "# 更换目录到数据文件夹\n",
    "import os\n",
    "os.getcwd()\n",
    "os.chdir('/Users/Zhang/Documents/华泰Project/数据/数据/估值')\n",
    "\n",
    "# 节选回测区间\n",
    "def date(df):\n",
    "    z = df.loc['2012-02-09':'2019-05-16']\n",
    "    return z\n",
    "\n",
    "# 因为拥有的个股不一样，所以要先去掉另一个多出来的个股，然后进行两个DataFrame之间除法运算\n",
    "# Return出来的数据类型是DataFrame\n",
    "def value(df1,df2):\n",
    "    if len(df1.columns) > len(df2.columns):\n",
    "        columns = df1.columns.difference(df2.columns)\n",
    "        df3 = df1.drop(columns,axis=1)\n",
    "        value = pd.DataFrame(df3.values/df2.values,columns = df3.columns,index = df3.index)\n",
    "    elif len(df1.columns) < len(df2.columns):\n",
    "        columns = df2.columns.difference(df1.columns)\n",
    "        df3 = df2.drop(columns,axis=1)\n",
    "        value = pd.DataFrame(df1.values/df3.values,columns = df3.columns,index = df3.index) \n",
    "    else:\n",
    "        value = pd.DataFrame(df1.values/df2.values,columns = df1.columns,index = df1.index)  \n",
    "    return value\n",
    "\n",
    "# 减少运算数据量，在因子后面_1来表示我们slice了data\n",
    "def slice(df):\n",
    "    df_1 = df.iloc[:,:300]\n",
    "    return df_1\n",
    "\n",
    "# 根据华泰金工研报的因子暴露度计算，是每个自然月的最后一个交易日进行计算，原因不知道？\n",
    "# 不明白为什么不可以自己每日的因子暴露度，准确率高，由于市值 = market price*# of shares outstanding。\n",
    "# market price of stock 每日都在变\n",
    "# 所以先按研报算法为准，我们先去除 除了自然月最后一个交易日的因子们\n",
    "\n",
    "\n",
    "# 寻找每个月最后一个交易日\n",
    "\n",
    "year = [2012,2013,2014,2015,2016,2017,2018,2019] ## Change year\n",
    "month = [1,2,3,4,5,6,7,8,9,10,11,12]\n",
    "\n",
    "Price = date(read_data(\"closePrice\"))\n",
    "Price['year'] = pd.DatetimeIndex(Price.index).year#['tradeDate'])#.year\n",
    "Price['month'] = pd.DatetimeIndex(Price.index).month\n",
    "Price['day'] = pd.DatetimeIndex(Price.index).day\n",
    "list_1 = []\n",
    "\n",
    "def return_list(j):\n",
    "    Find_month = Find_year.loc[Find_year['month'] == j]\n",
    "    z = Find_month.iloc[-1,:].name\n",
    "    list_1.append(z)\n",
    "    return list_1\n",
    "\n",
    "# since we start from Feb 2014 and end in May 2019\n",
    "for i in year:\n",
    "    Find_year = Price.loc[Price['year'] == i]\n",
    "    if i == 2012:\n",
    "        for j in month[1:]:\n",
    "            list_1 = return_list(j)\n",
    "    elif i == 2019:\n",
    "        for j in month[:4]:\n",
    "            list_1 = return_list(j)\n",
    "    else:\n",
    "        for j in month:\n",
    "            list_1 = return_list(j)\n",
    "            \n",
    "# create the function that will obtain data from every last trading day of month\n",
    "def month_end(df):\n",
    "    df1 = pd.DataFrame()\n",
    "    for i in list_1:\n",
    "        df_s = df.loc[df.index == i]\n",
    "        df1 = pd.concat([df1,df_s],axis = 0)\n",
    "    return df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 估值类因子"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EP 净利润(TTM)/总市值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NI = date(read_data(\"NIncome\"))\n",
    "MV = date(read_data(\"marketValue\"))\n",
    "EP = value(NI,MV)\n",
    "EP.index = NI.index\n",
    "EP.to_csv(r'/Users/Zhang/Documents/华泰Project/Computed_Factor/Fundamental/EP.csv')\n",
    "#减少运算数据量，在因子后面_1来表示我们slice了data\n",
    "EP_1 = slice(EP)\n",
    "EP_1 = month_end(EP_1)\n",
    "EP_1.to_csv(r'/Users/Zhang/Documents/华泰Project/Computed_Factor/Fundamental/EP_1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 市值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MV_1 = slice(MV)\n",
    "MV_1 = month_end(MV_1)\n",
    "MV_1.to_csv(r'/Users/Zhang/Documents/华泰Project/Computed_Factor/Fundamental/MV_1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EPcut 扣除非经常性损益后净利润(TTM)/总市值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NiAttr = date(read_data(\"niAttrPCut\"))\n",
    "EPcut = value(NiAttr,MV)\n",
    "EPcut.to_csv(r'/Users/Zhang/Documents/华泰Project/Computed_Factor/Fundamental/EPcut.csv')\n",
    "EPcut_1 = month_end(slice(EPcut))\n",
    "EPcut_1.to_csv(r'/Users/Zhang/Documents/华泰Project/Computed_Factor/Fundamental/EPcut_1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BP（净资产=所有者权益TTM）净资产/总市值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tsh = date(read_data(\"TShEquity\"))\n",
    "BP = value(Tsh,MV)\n",
    "BP.to_csv(r'/Users/Zhang/Documents/华泰Project/Computed_Factor/Fundamental/BP.csv')\n",
    "BP_1 = month_end(slice(BP))\n",
    "BP_1.to_csv(r'/Users/Zhang/Documents/华泰Project/Computed_Factor/Fundamental/BP_1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SP 营业收入(TTM)/总市值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev = date(read_data(\"revenue\"))\n",
    "SP = value(rev,MV)\n",
    "SP_1 = month_end(slice(SP))\n",
    "SP_1.to_csv(r'/Users/Zhang/Documents/华泰Project/Computed_Factor/Fundamental/SP_1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NCFP 净现金流(TTM)/总市值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NCE = date(read_data(\"NCEEndBal\"))\n",
    "NCFP = value(NCE,MV)\n",
    "NCFP_1 = month_end(slice(NCFP))\n",
    "NCFP_1.to_csv(r'/Users/Zhang/Documents/华泰Project/Computed_Factor/Fundamental/NCFP_1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OCFP 经营性现金流(TTM)/总市值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NCF = date(read_data(\"NCFOperateA\"))\n",
    "OCFP = value(NCF,MV)\n",
    "OCFP_1 = month_end(slice(OCFP))\n",
    "OCFP_1.to_csv(r'/Users/Zhang/Documents/华泰Project/Computed_Factor/Fundamental/OCFP_1.csv')\n",
    "# 无Dividends数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## G/PE 净利润(TTM)同比增长率/PE_TTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "G = date(read_data(\"niYoY\"))\n",
    "G = G.replace(0,np.nan)\n",
    "EPS = date(read_data(\"EPS\"))\n",
    "EPS = EPS.replace(0,np.nan) \n",
    "# EPS.eq(0).any().any()\n",
    "Price = date(read_data(\"closePrice\"))\n",
    "PE = value(Price,EPS)\n",
    "G_PE = value(G,PE)\n",
    "G_PE_1 = month_end(slice(G_PE))\n",
    "G_PE_1.to_csv(r'/Users/Zhang/Documents/华泰Project/Computed_Factor/Fundamental/G_PE_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "#In_captial = np.log(MV)\n",
    "os.chdir('/Users/Zhang/Documents/华泰Project/数据/数据/raw_data/raw_data/')\n",
    "Index = pd.read_csv(\"上证综指.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 整理Stock和Index Return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 整理Stock Return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Index = Index[['TRADE_DT','S_DQ_CLOSE']]\n",
    "Index['TRADE_DT'] = pd.to_datetime(Index['TRADE_DT'],format = '%Y%m%d',errors = 'ignore')\n",
    "Index.set_index('TRADE_DT',inplace=True)\n",
    "Stock_Return = Price.pct_change().iloc[1:]\n",
    "Stock_Return = Stock_Return.fillna(0)\n",
    "Stock_Return.index = pd.to_datetime(pd.Series(Stock_Return.index))# change dtype of object to datetime\n",
    "Stock_Return.to_csv(r'/Users/Zhang/Documents/华泰Project/Computed_Factor/Fundamental/Stock_Return.csv')\n",
    "Stock_Return_1 = month_end(slice(Stock_Return))\n",
    "Stock_Return_1.to_csv(r'/Users/Zhang/Documents/华泰Project/Computed_Factor/Fundamental/Stock_Return_1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## 整理Index DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Zhang/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:19: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n"
     ]
    }
   ],
   "source": [
    "# Index return\n",
    "Index_Return = Index['S_DQ_CLOSE'].pct_change().iloc[1:]\n",
    "Index_Return.to_csv(r'/Users/Zhang/Documents/华泰Project/Computed_Factor/Fundamental/Index_Return.csv')\n",
    "Index_Return_1 = month_end(Index_Return.loc['2012-02-09':'2019-05-16'])\n",
    "Index_Return_1.to_csv(r'/Users/Zhang/Documents/华泰Project/Computed_Factor/Fundamental/Index_Return_1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# 成长类因子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()\n",
    "os.chdir('/Users/Zhang/Documents/华泰Project/数据/数据/成长')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 营业收入(最新财报，YTD)同比增长率(%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "revenue = date(read_data(\"revenue\"))\n",
    "Sales_G_q = revenue\n",
    "Sales_G_q_1 = month_end(slice(Sales_G_q))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 净利润(最新财报，YTD)同比增长率(%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Profit_G_q = date(read_data(\"niYoY\"))\n",
    "Profit_G_q_1 = month_end(slice(Profit_G_q))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 经营性现金流(最新财报，YTD)同比增长率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OCF_G_q = date(read_data(\"NCFOperateA\"))\n",
    "OCF_G_q_1 = month_end(slice(OCF_G_q))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROE(最新财报，YTD)同比增长率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROE_G_q = date(read_data(\"ROEYOY\"))\n",
    "ROE_G_q_1 = month_end(slice(ROE_G_q))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 财务质量类因子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()\n",
    "os.chdir('/Users/Zhang/Documents/华泰Project/数据/数据/财务质量')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROE(最新财报，TTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROE = date(read_data('ROE'))\n",
    "ROE_1 = month_end(slice(ROE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROA(最新财报，TTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROA = date(read_data('ROA'))\n",
    "ROA_1 = month_end(slice(ROA))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 毛利率(最新财报，TTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grossprofitmargin_ttm = date(read_data('grossMARgin'))\n",
    "grossprofit_1 = month_end(slice(grossprofitmargin_ttm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 扣除非经常性损益后净利润率(最新财报，TTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profitmargin_ttm = date(read_data('npMARgin'))\n",
    "profitmargin_1 = month_end(slice(profitmargin_ttm ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 资产周转率(最新财报，TTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assetturnover_ttm = date(read_data('taTurnover'))\n",
    "assetturnover_1 = month_end(slice(assetturnover_ttm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 经营性现金流/净利润(最新财报，TTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Zhang/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:54: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n"
     ]
    }
   ],
   "source": [
    "operationcashflowratio_ttm = value(NCF,NI)\n",
    "ocf_1 = month_end(slice(operationcashflowratio_ttm ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 杠杆类因子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/Zhang/Documents/华泰Project/数据/数据/杠杆')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 总资产/净资产"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "TAssets = date(read_data('TAssets'))\n",
    "TAssets_1 = month_end(slice(TAssets))\n",
    "Tsh_1 = month_end(slice(Tsh)) #净资产\n",
    "\n",
    "for i in range(TAssets_1.shape[1]):\n",
    "    financial_lev_list = []\n",
    "    a = TAssets_1.iloc[:,i].values\n",
    "    b = Tsh_1.iloc[:,i].values\n",
    "    c = np.divide(a,b,out = np.zeros_like(a),where=b!=0) # divide cal anywhere 'where' b!=0\n",
    "    #financial_lev_list.append(c)\n",
    "    if i == 0:\n",
    "        financial_lev_df = pd.Series(c)\n",
    "    else:\n",
    "        c = pd.Series(c)\n",
    "        financial_lev_df = pd.concat([financial_lev_df,c],axis = 1)\n",
    "\n",
    "financial_lev_df.index = TAssets_1.index\n",
    "financial_lev_df.columns = TAssets_1.columns       \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## debtequityratio 非流动负债/净资产"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Zhang/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:54: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000001</th>\n",
       "      <th>000002</th>\n",
       "      <th>000003</th>\n",
       "      <th>000004</th>\n",
       "      <th>000005</th>\n",
       "      <th>000006</th>\n",
       "      <th>000007</th>\n",
       "      <th>000008</th>\n",
       "      <th>000009</th>\n",
       "      <th>000010</th>\n",
       "      <th>...</th>\n",
       "      <th>000712</th>\n",
       "      <th>000713</th>\n",
       "      <th>000715</th>\n",
       "      <th>000716</th>\n",
       "      <th>000717</th>\n",
       "      <th>000718</th>\n",
       "      <th>000719</th>\n",
       "      <th>000720</th>\n",
       "      <th>000721</th>\n",
       "      <th>000722</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-02-28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.349106</td>\n",
       "      <td>-0.210472</td>\n",
       "      <td>0.004977</td>\n",
       "      <td>0.000511</td>\n",
       "      <td>0.646285</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.262816</td>\n",
       "      <td>0.002747</td>\n",
       "      <td>...</td>\n",
       "      <td>0.318653</td>\n",
       "      <td>0.021213</td>\n",
       "      <td>0.010450</td>\n",
       "      <td>0.142776</td>\n",
       "      <td>0.249173</td>\n",
       "      <td>0.790872</td>\n",
       "      <td>0.002293</td>\n",
       "      <td>1.857254</td>\n",
       "      <td>0.018263</td>\n",
       "      <td>0.065855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-03-31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.425306</td>\n",
       "      <td>-0.210472</td>\n",
       "      <td>0.004977</td>\n",
       "      <td>0.000511</td>\n",
       "      <td>0.645327</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.262816</td>\n",
       "      <td>0.002747</td>\n",
       "      <td>...</td>\n",
       "      <td>0.466298</td>\n",
       "      <td>0.021213</td>\n",
       "      <td>0.011411</td>\n",
       "      <td>0.142776</td>\n",
       "      <td>0.249173</td>\n",
       "      <td>0.790872</td>\n",
       "      <td>0.002293</td>\n",
       "      <td>1.857254</td>\n",
       "      <td>0.018263</td>\n",
       "      <td>0.065677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-04-30</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.424400</td>\n",
       "      <td>-0.211586</td>\n",
       "      <td>0.227034</td>\n",
       "      <td>0.000582</td>\n",
       "      <td>0.552894</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.409105</td>\n",
       "      <td>0.001330</td>\n",
       "      <td>...</td>\n",
       "      <td>0.293525</td>\n",
       "      <td>0.026675</td>\n",
       "      <td>0.021760</td>\n",
       "      <td>0.070466</td>\n",
       "      <td>0.102810</td>\n",
       "      <td>1.264583</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>2.246931</td>\n",
       "      <td>0.013500</td>\n",
       "      <td>0.060351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-05-31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-06-30</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.424400</td>\n",
       "      <td>-0.211586</td>\n",
       "      <td>0.227034</td>\n",
       "      <td>0.000582</td>\n",
       "      <td>0.552894</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.409105</td>\n",
       "      <td>0.001330</td>\n",
       "      <td>...</td>\n",
       "      <td>0.293525</td>\n",
       "      <td>0.025619</td>\n",
       "      <td>0.021760</td>\n",
       "      <td>0.070466</td>\n",
       "      <td>0.102810</td>\n",
       "      <td>1.264583</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>2.246931</td>\n",
       "      <td>0.013500</td>\n",
       "      <td>0.060351</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            000001    000002    000003    000004    000005    000006  000007  \\\n",
       "2014-02-28     NaN  0.349106 -0.210472  0.004977  0.000511  0.646285     NaN   \n",
       "2014-03-31     NaN  0.425306 -0.210472  0.004977  0.000511  0.645327     NaN   \n",
       "2014-04-30     NaN  0.424400 -0.211586  0.227034  0.000582  0.552894     NaN   \n",
       "2014-05-31     NaN       NaN       NaN       NaN       NaN       NaN     NaN   \n",
       "2014-06-30     NaN  0.424400 -0.211586  0.227034  0.000582  0.552894     NaN   \n",
       "\n",
       "            000008    000009    000010  ...    000712    000713    000715  \\\n",
       "2014-02-28     NaN  0.262816  0.002747  ...  0.318653  0.021213  0.010450   \n",
       "2014-03-31     NaN  0.262816  0.002747  ...  0.466298  0.021213  0.011411   \n",
       "2014-04-30     NaN  0.409105  0.001330  ...  0.293525  0.026675  0.021760   \n",
       "2014-05-31     NaN       NaN       NaN  ...       NaN       NaN       NaN   \n",
       "2014-06-30     NaN  0.409105  0.001330  ...  0.293525  0.025619  0.021760   \n",
       "\n",
       "              000716    000717    000718    000719    000720    000721  \\\n",
       "2014-02-28  0.142776  0.249173  0.790872  0.002293  1.857254  0.018263   \n",
       "2014-03-31  0.142776  0.249173  0.790872  0.002293  1.857254  0.018263   \n",
       "2014-04-30  0.070466  0.102810  1.264583  0.000357  2.246931  0.013500   \n",
       "2014-05-31       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "2014-06-30  0.070466  0.102810  1.264583  0.000357  2.246931  0.013500   \n",
       "\n",
       "              000722  \n",
       "2014-02-28  0.065855  \n",
       "2014-03-31  0.065677  \n",
       "2014-04-30  0.060351  \n",
       "2014-05-31       NaN  \n",
       "2014-06-30  0.060351  \n",
       "\n",
       "[5 rows x 300 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TNCL = date(read_data('TNCL'))\n",
    "TNCL_1 = month_end(slice(TNCL))\n",
    "\n",
    "for i in range(TNCL_1.shape[1]):\n",
    "    TNCL_list = []\n",
    "    a = TNCL_1.iloc[:,i].values\n",
    "    b = Tsh_1.iloc[:,i].values\n",
    "    c = np.divide(a,b,out = np.zeros_like(a),where=b!=0) # divide cal anywhere 'where' b!=0\n",
    "    #financial_lev_list.append(c)\n",
    "    if i == 0:\n",
    "        debt_equity_df = pd.Series(c)\n",
    "    else:\n",
    "        c = pd.Series(c)\n",
    "        debt_equity_df = pd.concat([debt_equity_df,c],axis = 1)\n",
    "\n",
    "debt_equity_df.index = TNCL_1.index\n",
    "debt_equity_df.columns = TNCL_1.columns    \n",
    "debt_equity_df.head()\n",
    "# cashratio 现金比率 暂无数据\n",
    "\n",
    "# currentratio 流动比率 暂无数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 动量反转因子"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 个股 60 个月收益与上证综指回归的截距项与Beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.linear_model import LinearRegression\n",
    "start_time = time.time()\n",
    "cons = np.ones((60,1)).reshape(-1,1)\n",
    "Stock_Return_1 = Stock_Return_1.fillna(0)\n",
    "Index_Return_1 = Index_Return_1.fillna(0)\n",
    "beta_Df = pd.DataFrame()\n",
    "alpha_Df = pd.DataFrame()\n",
    "#print('Beta_df shape'+str(beta_Df))\n",
    "for i in range(Stock_Return_1.shape[1]):\n",
    "    beta = []\n",
    "    alpha = []\n",
    "    beta_Series = pd.Series()\n",
    "    alpha_Series = pd.Series()\n",
    "    for j in range((Stock_Return_1.shape[0])-60): \n",
    "        S_R = np.array(Stock_Return_1.iloc[j:60+j,i]).reshape(-1,1)\n",
    "        X = np.concatenate((S_R,cons),axis=1)\n",
    "        Y = np.array(Index_Return_1.iloc[j:60+j])\n",
    "        reg = LinearRegression().fit(X,Y)\n",
    "        beta.append(reg.coef_[0])\n",
    "        alpha.append(reg.intercept_)\n",
    "        \n",
    "    beta_Series = pd.Series(beta)\n",
    "    #print('beta series shape' + str(beta_Series.shape))\n",
    "\n",
    "    alpha_Series = pd.Series(alpha)\n",
    "    #print('alpha series shape' + str(alpha_Series.shape))\n",
    "    beta_Df = pd.concat([beta_Df,beta_Series],axis = 1)\n",
    "    alpha_Df = pd.concat([alpha_Df,alpha_Series],axis = 1)\n",
    "\n",
    "beta_Df.index = Stock_Return_1.iloc[60:].index\n",
    "alpha_Df.index = Stock_Return_1.iloc[60:].index # reset index + check number of index\n",
    "beta_Df.columns = Stock_Return_1.columns \n",
    "alpha_Df.columns = Stock_Return_1.columns\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "#np.array(beta).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 截距项（HAlpha）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_Df.to_csv(r'/Users/Zhang/Documents/华泰Project/Computed_Factor/Fundamental/Halpha.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1.5961060523986816 seconds ---\n"
     ]
    }
   ],
   "source": [
    "beta_Df.to_csv(r'/Users/Zhang/Documents/华泰Project/Computed_Factor/Fundamental/beta.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 个股最近N 个月收益率，N=1，3，6，12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_m(df,m):\n",
    "    dff = pd.DataFrame()\n",
    "    #Nested_list = []\n",
    "    for i in range(df.shape[1]):\n",
    "        list_1 = []\n",
    "        Series = pd.Series() # need to reinitialize\n",
    "        for j in range(df.shape[0]-m):\n",
    "            n = df.iloc[j:m+j,i].cumprod().iloc[-1]\n",
    "            list_1.append(n)\n",
    "        #Nested_list.append(list_1)\n",
    "        #dff = pd.DataFrame(Nested_list)\n",
    "        Series = pd.Series(list_1)\n",
    "        dff = pd.concat([dff,Series],axis = 1)       \n",
    "   \n",
    "    dff.index = df.iloc[m:].index # reset index + check number of index\n",
    "    dff.columns = df.columns # reset columns + check number of columns\n",
    "    return dff\n",
    "\n",
    "return_1 = return_m(Stock_Return_1,1)\n",
    "#return_3 = return_m(Stock_Return_1,3)\n",
    "#return_6 = return_m(Stock_Return_1,6)\n",
    "#return_12 = return_m(Stock_Return_1,12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# grouby turnover dataframe by stock\n",
    "### 如果数据源都呈一列，使用这个cell可以整理数据，纵轴为个股，横轴为时间\n",
    "### 用来转换raw data\n",
    "# 改变turnover到你想要的csv\n",
    "os.chdir('/Users/Zhang/Documents/华泰Project/数据/数据/raw_data/raw_data/')\n",
    "turnover = pd.read_csv(\"换手率.csv\")\n",
    "turnover['mddate'] = pd.to_datetime(turnover['mddate'],format = '%Y%m%d',errors = 'ignore')\n",
    "print(type(turnover.stock.unique()))\n",
    "\n",
    "s = turnover.groupby(['stock']) \n",
    "\n",
    "def stock_i(df): # function to modify df\n",
    "    stock_name = df.iloc[0]['stock']\n",
    "    new_df = df.rename(columns = {'turn' :stock_name})\n",
    "    new_df.drop(['stock'],axis = 1,inplace = True)   \n",
    "    return new_df\n",
    "\n",
    "stock_names = turnover.stock.unique() # get individual stock id\n",
    "\n",
    "old_df = pd.DataFrame() # initiallize \n",
    "for i in range(len(stock_names)):\n",
    "    df = s.get_group(stock_names[i]) # find the individual stock data from 2011 to 2019\n",
    "    if i == 0:\n",
    "        new_df = stock_i(df)\n",
    "        old_df = new_df\n",
    "    else:\n",
    "        new_df = stock_i(df)\n",
    "        old_df = pd.merge(old_df,new_df,on = 'mddate',how = 'left')\n",
    "\n",
    "old_df = old_df.set_index('mddate')\n",
    "\n",
    "# 记得保存整理好的数据\n",
    "old_df.to_csv(r'/Users/Zhang/Documents/华泰Project/数据/数据/raw_data/raw_data/Turnover_modified.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECKPOINT\n",
    "# CHECKPOINT\n",
    "# CHECKPOINT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 个股最近N 个月内用每日换手率乘以每日收益率求算术平均值，N=1，3，6，12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1285, 300)\n",
      "(63, 300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Zhang/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:20: RuntimeWarning: Mean of empty slice\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-0cb9209a8bcd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0mReturn_cal_turnover\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStock_Return\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns_1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mwgt_return_1m\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwgt_return_Nm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mturnover_cal_Return\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mReturn_cal_turnover\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0mwgt_return_1m\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'/Users/Zhang/Documents/华泰Project/Computed_Factor/Fundamental/wgt_return_1m'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m#wgt_return_3m = wgt_return_Nm(turnover_cal_Return,Return_cal_turnover,3)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-72-0cb9209a8bcd>\u001b[0m in \u001b[0;36mwgt_return_Nm\u001b[0;34m(turnover_cal_Return, Return_cal_turnover, m)\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                 \u001b[0mwgt_return_series\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwgt_return_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0mwgt_return_Df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwgt_return_Df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwgt_return_series\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwgt_return_Df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, join_axes, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    226\u001b[0m                        \u001b[0mkeys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m                        \u001b[0mverify_integrity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m                        copy=copy, sort=sort)\n\u001b[0m\u001b[1;32m    229\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, objs, axis, join, join_axes, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0;31m# consolidate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m             \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m             \u001b[0mndims\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_consolidate\u001b[0;34m(self, inplace)\u001b[0m\n\u001b[1;32m   5154\u001b[0m         \u001b[0minplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_bool_kwarg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inplace'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5155\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5156\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5157\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5158\u001b[0m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_consolidate_inplace\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   5136\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5138\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_protect_consolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5140\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_consolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_protect_consolidate\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m   5125\u001b[0m         \"\"\"\n\u001b[1;32m   5126\u001b[0m         \u001b[0mblocks_before\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5127\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5128\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mblocks_before\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5129\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mf\u001b[0;34m()\u001b[0m\n\u001b[1;32m   5134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5135\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5136\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5138\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_protect_consolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mconsolidate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    922\u001b[0m         \u001b[0mbm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m         \u001b[0mbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_consolidated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m         \u001b[0mbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    925\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m_consolidate_inplace\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_consolidated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 929\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_consolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    930\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_consolidated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_known_consolidated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m_consolidate\u001b[0;34m(blocks)\u001b[0m\n\u001b[1;32m   1897\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_can_consolidate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_blocks\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrouper\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1898\u001b[0m         merged_blocks = _merge_blocks(list(group_blocks), dtype=dtype,\n\u001b[0;32m-> 1899\u001b[0;31m                                       _can_consolidate=_can_consolidate)\n\u001b[0m\u001b[1;32m   1900\u001b[0m         \u001b[0mnew_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerged_blocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1901\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_blocks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36m_merge_blocks\u001b[0;34m(blocks, dtype, _can_consolidate)\u001b[0m\n\u001b[1;32m   3148\u001b[0m         \u001b[0margsort\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_mgr_locs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3149\u001b[0m         \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3150\u001b[0;31m         \u001b[0mnew_mgr_locs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_mgr_locs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3152\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmake_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_mgr_locs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "os.chdir('/Users/Zhang/Documents/华泰Project/数据/数据/股票数据/')\n",
    "def date(df):\n",
    "    z = df.loc['2014-02-10':'2019-05-16']\n",
    "    return z\n",
    "\n",
    "turnover = date(read_data('turnoverRate'))\n",
    "turnover_1 = slice(turnover)\n",
    "\n",
    "def wgt_return_Nm(turnover_cal_Return,Return_cal_turnover,m):\n",
    "    for i in range(300): #range(3622): # 3670\n",
    "        wgt_return_list = []\n",
    "        for j in range(200):#range(2013-m*20): # 2013-1*20\n",
    "            turnover_array = np.array(turnover_cal_Return.iloc[j:m*20+j,i]).reshape(-1,1)\n",
    "            return_array = np.array(Return_cal_turnover.iloc[j:m*20+j,i]).reshape(-1,1)\n",
    "            wgt_return_list.append(np.nanmean(turnover_array*return_array))\n",
    "            if i == 0:\n",
    "                wgt_return_series = pd.Series(wgt_return_list)\n",
    "                wgt_return_Df = wgt_return_series\n",
    "            else:\n",
    "                wgt_return_series = pd.Series(wgt_return_list)\n",
    "                wgt_return_Df = pd.concat([wgt_return_Df,wgt_return_series],axis = 1)\n",
    "    return wgt_return_Df\n",
    "\n",
    "turnover_cal_Return = turnover_1.iloc[1:]\n",
    "print(turnover_cal_Return.shape)\n",
    "print(Return_cal_turnover.shape)\n",
    "columns_1 = Stock_Return.columns.difference(turnover_cal_Return.columns)\n",
    "Return_cal_turnover = Stock_Return.drop(columns_1,axis=1)\n",
    "\n",
    "wgt_return_1m = wgt_return_Nm(turnover_cal_Return,Return_cal_turnover,1)\n",
    "wgt_return_1m.to_csv(r'/Users/Zhang/Documents/华泰Project/Computed_Factor/Fundamental/wgt_return_1m')\n",
    "#wgt_return_3m = wgt_return_Nm(turnover_cal_Return,Return_cal_turnover,3)\n",
    "#wgt_return_3m.to_csv(r'/Users/Zhang/Documents/华泰Project/Computed_Factor/Fundamental/wgt_return_3m')\n",
    "#wgt_return_6m = wgt_return_Nm(turnover_cal_Return,Return_cal_turnover,6)\n",
    "#wgt_return_6m.to_csv(r'/Users/Zhang/Documents/华泰Project/Computed_Factor/Fundamental/wgt_return_6m')\n",
    "#wgt_return_12m = wgt_return_Nm(turnover_cal_Return,Return_cal_turnover,12)\n",
    "#wgt_return_12m.to_csv(r'/Users/Zhang/Documents/华泰Project/Computed_Factor/Fundamental/wgt_return_12m')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 动量反转\n",
    "个股最近N个月内用每日换手率乘以函数exp(-x_i/N/4)再乘以每日\n",
    "#收益率求算术平均值，x_i 为该日距离截面日的交易日的个数，N=1，3，6，12\n",
    "\n",
    "#exp_wgt_return_Nm ="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 波动率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7387710"
      ]
     },
     "execution_count": 538,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 特质波动率——个股最近N 个月内用日频收益率对Fama French\n",
    "# 三因子回归的残差的标准差，N=1，3，6，12\n",
    "#std_FF3factor_Nm = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 计算股价"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], dtype: float64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "std_list = []\n",
    "In_Price = np.log(Price)\n",
    "stock_array = Stock_Return.iloc[0:20,1]\n",
    "std_m = np.std(stock_array)\n",
    "std_list = std_list.append(std_m)\n",
    "std_list = pd.Series(std_list)\n",
    "print(std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 个股最近N 个月的日收益率序列标准差，N=1，3，6，12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "def std_Nm(Stock_Return,m):\n",
    "    std_record = pd.Series()\n",
    "    for i in range(20): #range(3670): # 3670\n",
    "        std_list = []\n",
    "        for j in range(100): #range(2013-m*20): # 2013-60*20\n",
    "            stock_array = np.array(Stock_Return.iloc[j:m*20+j,i]).reshape(-1,1)\n",
    "            std_m = np.std(stock_array)\n",
    "            std_list.append(std_m)\n",
    "        std_series = pd.Series(std_list)\n",
    "        std_record = pd.concat([std_record,std_series],axis = 1)\n",
    "            \n",
    "    return std_record\n",
    "\n",
    "# 计算1个月日收益率序列标准差\n",
    "std_1m = std_Nm(Stock_Return_1,1)\n",
    "\n",
    "# 计算3个月日收益率序列标准差\n",
    "#std_3m = std_Nm(Stock_Return,3)\n",
    "\n",
    "# 计算6个月日收益率序列标准差\n",
    "#std_6m = std_Nm(Stock_Return,6)\n",
    "\n",
    "# 计算12个月日收益率序列标准差\n",
    "#std_12m = std_Nm(Stock_Return,12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 504,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 因为使用Talib时候，input如果全为NaN，程序报错，所以先check array是否全为NaN\n",
    "# 如果全为NaN，就不计算这个array\n",
    "s = Price.iloc[:,1000].isnull().all()\n",
    "print(s)\n",
    "# check Price data if there is any column with all NaN values\n",
    "count = 0\n",
    "for i in range(Price.shape[1]):\n",
    "    z = Price.iloc[:,i].isnull().all()\n",
    "    if not z:\n",
    "        pass\n",
    "    else:\n",
    "        count += 1\n",
    "count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 技术指标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Price' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-8eb39299b7dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtalib\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m \u001b[0;31m# setup rollingwindow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPrice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mcols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPrice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mMACD_DataFrame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Price' is not defined"
     ]
    }
   ],
   "source": [
    "import talib as ta\n",
    "n = 20 # setup rollingwindow\n",
    "rows = Price.shape[0]\n",
    "cols = Price.shape[1]\n",
    "MACD_DataFrame = pd.DataFrame()\n",
    "# use pd dataframe or Series to concat\n",
    "\n",
    "for i in range(cols):\n",
    "    Nan = Price.iloc[:,i].isnull().all() #check if there is any NaN in column i\n",
    "    \n",
    "    if not Nan:\n",
    "        Price_array = np.zeros((rows,))\n",
    "        #Price_stock_name = Price.columns.values[i] # find the stock name\n",
    "        Price_array = Price.values[:,i]\n",
    "        MACD_series = pd.Series(ta.MACD(Price_array))#,timeperiod = n))\n",
    "      \n",
    "        #MACD_series.rename(Price_stock_name)\n",
    "        if i == 0:\n",
    "            MACD_DataFrame = MACD_series\n",
    "        else:\n",
    "            MACD_DataFrame = pd.concat([MACD_DataFrame,MACD_series],axis = 1)\n",
    "    else:\n",
    "        MACD_zeros = pd.Series(np.zeros((rows,)))\n",
    "        MACD_DataFrame = pd.concat([MACD_DataFrame,MACD_zeros],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_stock_name_date(df):\n",
    "    df.columns = Price.columns\n",
    "    date = Price.index\n",
    "    df = df.set_index(date)\n",
    "    return df\n",
    "MACD_DataFrame = add_stock_name_date(MACD_DataFrame)\n",
    "\n",
    "MACD_DataFrame.to_csv(r'/Users/Zhang/Documents/华泰Project/Computed_Factor/Technical/MACD_20.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "import talib as ta\n",
    "n = 20 # setup rollingwindow\n",
    "rows = Price.shape[0]\n",
    "cols = Price.shape[1]\n",
    "RSI_DataFrame = pd.DataFrame()\n",
    "# use pd dataframe or Series to concat\n",
    "for i in range(cols):\n",
    "    Nan = Price.iloc[:,i].isnull().all() #check if there is any NaN in column i\n",
    "    \n",
    "    if not Nan:\n",
    "        Price_array = np.zeros((rows,))\n",
    "        #Price_stock_name = Price.columns.values[i] # find the stock name\n",
    "        Price_array = Price.values[:,i]\n",
    "        RSI_array = ta.RSI(Price_array,timeperiod = n)\n",
    "        RSI_series = pd.Series(RSI_array)\n",
    "        #RSI_series.rename(Price_stock_name)\n",
    "        if i == 0:\n",
    "            RSI_DataFrame = RSI_series\n",
    "        else:\n",
    "            RSI_DataFrame = pd.concat([RSI_DataFrame,RSI_series],axis = 1)\n",
    "    else:\n",
    "        RSI_zeros = pd.Series(np.zeros((rows,)))\n",
    "        RSI_DataFrame = pd.concat([RSI_DataFrame,RSI_zeros],axis = 1)\n",
    "\n",
    "#RSI_DataFrame \n",
    "RSI_DataFrame.columns = Price.columns\n",
    "date = Price.index\n",
    "RSI_DataFrame = RSI_DataFrame.set_index(date)\n",
    "RSI_DataFrame.to_csv(r'/Users/Zhang/Documents/华泰Project/Computed_Factor/Technical/RSI_20.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 830,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['turn'], dtype='object')"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
